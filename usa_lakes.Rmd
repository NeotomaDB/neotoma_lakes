---
title: "US Lake sizes in Neotoma"
author: "Simon Goring"
output:
  html_document:
    code_folding: null
    keep_md: false
    mathjax: null
    self_contained: true
    number_sections: no
    highlight: null
    toc: no
    includes:
      before_body: styles/header.html
      after_body: styles/footer.html
    theme: yeti
    md_extensions: -autolink_bare_uris
---

This is a rewrite of the original document, that attempts to match Neotoma sites with their associated lakes within an RMarkdown document for more efficient review and analysis.

```{r loadLibrary, messages = FALSE}

knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(rgdal)
library(neotoma)
library(dplyr)
library(purrr)
library(sp)
library(datasets)
library(sf)
library(leaflet)

```

For this work we download Neotoma datasets using the `neotoma` R package.  Datasets are downloaded from Neotoma state by state, so that the Neotoma state level data intersects with the US National Hydrology database.

The code to align lakes with their associated Neotoma sites can be found in `R/us_state_lakes.R`.

```{r sourceState}
source('R/us_state_lakes.R')
```

`us_state_lakes()` accesses shapefiles from the National Hydrography Dataset for each individual state in the United States.  The function uses the `sf` package to open the shapefiles, perform an intersection between the Neotoma points and the shapefiles, and then returns information about the lakes with which each Neotoma site intersects.

The function also looks for any lakes within the state that have the same name as the Neotoma site.

### Executing the Function

The script uses the entire set of US state abbreviations.  Because the script takes a significant amount of time, and the downloads are quite large, this script is run through a loop, saving the interim output of the `runs` list using a date-time stamped `rds` file.

Because the script runs on the Penn State CEI servers we use a Linux script to start the script, so it can run in the background:

```bash
nohup Rscript -e "rmarkdown::render('usa_lakes.Rmd')" > lakerender.out 2>&1 &
```

```{r runStates, results = "hide"}

# state.abb is a data element in R for US state abbreviations.
states <- state.abb

data_run <- Sys.Date()

for (i in 1:length(states)) {

  cat("Running data for", states[i], "\n")
  statematch <- list.files("data/lake_match",
                           pattern = paste0(states[i], ".rds"))

  if (length(statematch) == 0) {

    run <- try(us_state_lakes(states[i]))

    if ("try-error" %in% class(run)) {
      run <- data.frame(stid = NA, dsid = NA, state = states[i])
    }

    saveRDS(run,
            paste0("data/lake_match/run",
                   Sys.Date(), "_",
                   states[i], ".rds"))

    # Clean temprary files:
    file.remove(list.files(tempdir(), full.names = TRUE, recursive = TRUE))
    file.remove(list.files("Shape", full.names = TRUE, recursive = TRUE))
    gc()

  } else {
    cat("State has already been run.\n")
  }

}

```

Once each state has been checked and the individual output files have been written, the script then reads each file and binds them together:

```{r loadResults, results="hide"}

statefiles <- list.files("data/lake_match",
                         pattern = ".rds",
                         full.names = TRUE)

runs <- list()

for(i in 1:length(statefiles)) {
  runs[[i]] <- readRDS(statefiles[i])
}

areas <- statefiles %>%
  map(function(x) {
     aa <- try(readRDS(x))
     if (!"try-error" %in% class(aa)) {
       colnames(aa) <- tolower(colnames(aa))
     } else {
       aa <- NULL
     }
     return(aa)
   }) %>%
  bind_rows()

areas_clean <- areas %>%
  dplyr::select(stid, dsid, site.name,
                long, lat, state,
                gnis_name, gnis_id, areasqkm,
                dist_match, data_source,
              geometry)

areas_clean$areaha <- areas_clean$areasqkm * 100

readr::write_csv(areas_clean, "data/output/usa_pollensites.csv")

```

## Summary Results

```{r stateTable, echo = FALSE}
areas_clean %>%
  group_by(state) %>%
  summarise(sites = n(),
            matched = sum(!is.na(gnis_id))) %>%
  DT::datatable()
```

### Matched Lakes

We have a total of `r sum(!is.na(areas_clean$gnis_id))` datasets that can be directly aligned with the National Hydrology Dataset.

```{r matchMap, echo = FALSE}

matched <- areas_clean %>%
  filter(!is.na(gnis_id)) %>%
  mutate(info = paste0("<b>", site.name, "</b><br>State:<strong>",
                       state, "<br>",
                           "Link: <a href=apps.neotomadb.org/explorer/?dsid=",
                           dsid, ">Explorer</a>")) %>%
  select(lat, long, info)

leaflet(matched) %>%
  addProviderTiles("Esri.WorldImagery") %>%
  addMarkers(lat = ~lat,
             lng = ~long,
             clusterOptions = markerClusterOptions(),
             popup = ~info)
```

```{r matchedTable, echo=FALSE}

areas_clean %>%
  filter(!is.na(gnis_id)) %>%
  select(stid, dsid, state, site.name, gnis_name, areaha) %>%
  DT::datatable()
```

## Unmatched Lakes

We have a total of `r sum(is.na(areas_clean$gnis_id))` datasets that could not be aligned with the National Hydrology Dataset.

```{r unmatchMap, echo=FALSE}

unmatched <- areas_clean %>%
  filter(is.na(gnis_id)) %>%
  mutate(info = paste0("<b>", site.name, "</b><br>State:<strong>",
                       state, "<br>",
                           "Link: <a href=apps.neotomadb.org/explorer/?dsid=",
                           dsid, ">Explorer</a>")) %>%
  select(lat, long, info)

leaflet(unmatched) %>%
  addProviderTiles("Esri.WorldImagery") %>%
  addMarkers(lat = ~lat,
             lng = ~long,
             clusterOptions = markerClusterOptions(),
             popup = ~info)
```

```{r unmatchedTable, echo=FALSE}

areas_clean %>%
  filter(is.na(gnis_id)) %>%
  select(stid, dsid, state, site.name, gnis_name, areaha) %>%
  DT::datatable()
```
